{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract New York Times articles related to bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/shujinkou/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shujinkou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-719931c382a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'key'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pprint\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from key import app_key\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = app_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate list\n",
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_articles(articles, params):\n",
    "    \"\"\"\n",
    "    Retrieves article information related to bitcoin from NYT through several api requests.\n",
    "    \n",
    "    Parameters:\n",
    "    articles (list): A list to hold the dictionaries/json response\n",
    "    params (dictionary): The api request params. This is modified within the function to accomedate pagenation\n",
    "    \n",
    "    returns: None\n",
    "    effects: appends articles list with new json responses\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # i runs through the response \"pages\". each requests gives 10 articles\n",
    "    for i in tqdm.tqdm(range(99)):\n",
    "        params[\"page\"] = i\n",
    "        endpoint = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    "        response = requests.get(endpoint, params=params).json()\n",
    "        # loop through each article in an individual api response\n",
    "        for article_num in range(len(response['response']['docs'])):\n",
    "            pub_date = response['response']['docs'][article_num]['pub_date']\n",
    "            headline = response['response']['docs'][article_num]['headline']['main']\n",
    "            abstract = response['response']['docs'][article_num]['abstract']\n",
    "            lead_paragraph = response['response']['docs'][article_num]['lead_paragraph']\n",
    "            article_url = response['response']['docs'][article_num]['web_url']\n",
    "            # append the dictionary to the list\n",
    "            articles.append({\"date\": pub_date, \"headline\": headline, \"abstract\": abstract,\n",
    "                            \"lead_paragraph\":lead_paragraph, \"url\": article_url})\n",
    "        time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [00:15<12:13,  7.56s/it]"
     ]
    }
   ],
   "source": [
    "# retreive the first ~1000 results\n",
    "params = {\"q\":\"bitcoin\", \"api-key\": api_key, \"sort\": \"newest\"}\n",
    "get_articles(articles, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreive the last ~500 results\n",
    "params['end_date'] = '20141002'\n",
    "get_articles(articles, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this block to check the oldest date requested. This date \n",
    "# is then used to make a new request with a end_date param\n",
    "# it also sorts the entries by date\n",
    "articles_temp = articles\n",
    "articles_temp.sort(key=lambda item:item['date'], reverse=True)\n",
    "articles_temp[-1]['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example document\n",
    "articles[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "with open(\"articles.json\", \"w\") as json_data:\n",
    "    json.dump(articles, json_data)\n",
    "df = pd.read_json(\"articles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "df.to_csv(\"articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(article):\n",
    "    \"\"\"\n",
    "    Determines the sentiment of a NYT headline\n",
    "    \n",
    "    Parameters:\n",
    "    article (dict): an element of the articles list\n",
    "    \n",
    "    returns: returns the article dictionary with the ['sentiment'] key included.\n",
    "    sentiment is the probability that the headline is a \"positive\" opinion. \n",
    "    \n",
    "    \"\"\"\n",
    "    article['sentiment'] = TextBlob(article['headline'], analyzer=NaiveBayesAnalyzer()).sentiment.p_pos\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8942141448021957"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example sentiment anlysis. This has a .89% chance of being positive.\n",
    "TextBlob(articles[0]['headline'], analyzer=NaiveBayesAnalyzer()).sentiment.p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment anlysis was done in parallel, since the naivebayesanalyzer is slow.\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "pool = ThreadPool()\n",
    "# utalize all cores\n",
    "results = pool.map(get_sentiment, articles)\n",
    "#close the pool and wait for the work to finish\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2011-05-30T00:37:00+0000',\n",
       " 'headline': 'Some Faint Praise for Mr. Ballmer',\n",
       " 'abstract': 'David Einhorn’s critique of Steve Ballmer is on target even if he’s far from the only chief executive who has struggled to make the most of a franchise.',\n",
       " 'lead_paragraph': 'Microsoft has missed too many opportunities under Steve Ballmer’s stewardship. It’s a fair criticism reignited last week by the hedge fund boss, David Einhorn, who called for the software giant’s chief executive to step down. But that doesn’t necessarily mean Mr. Ballmer will go. Based on total return to shareholders, other long-time company bosses, including Jeff Immelt at General Electric, have fared worse.',\n",
       " 'url': 'https://www.nytimes.com/2011/05/30/business/economy/30views.html',\n",
       " 'sentiment': 0.6809889669735206}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json with sentiment anlysis completed\n",
    "with open(\"articles_with_sentiment.json\", \"w\") as json_data:\n",
    "    json.dump(results, json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03576842788467115"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"\", analyzer=NaiveBayesAnalyzer()).sentiment.p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
